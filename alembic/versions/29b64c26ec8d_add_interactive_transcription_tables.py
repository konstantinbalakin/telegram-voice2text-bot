"""add_interactive_transcription_tables

Revision ID: 29b64c26ec8d
Revises: 0fde9e5effe5
Create Date: 2025-12-02 22:02:02.132942

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = "29b64c26ec8d"
down_revision: Union[str, None] = "0fde9e5effe5"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "transcription_segments",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("usage_id", sa.Integer(), nullable=False),
        sa.Column("segment_index", sa.Integer(), nullable=False),
        sa.Column("start_time", sa.Float(), nullable=False),
        sa.Column("end_time", sa.Float(), nullable=False),
        sa.Column("text", sa.String(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(["usage_id"], ["usage.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_transcription_segments_usage_id"),
        "transcription_segments",
        ["usage_id"],
        unique=False,
    )
    # Add unique constraint for (usage_id, segment_index)
    with op.batch_alter_table("transcription_segments", schema=None) as batch_op:
        batch_op.create_unique_constraint(
            "uq_transcription_segments_usage_segment", ["usage_id", "segment_index"]
        )

    op.create_table(
        "transcription_states",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("usage_id", sa.Integer(), nullable=False),
        sa.Column("message_id", sa.Integer(), nullable=False),
        sa.Column("chat_id", sa.Integer(), nullable=False),
        sa.Column("active_mode", sa.String(length=20), nullable=False),
        sa.Column("length_level", sa.String(length=10), nullable=False),
        sa.Column("emoji_level", sa.Integer(), nullable=False),
        sa.Column("timestamps_enabled", sa.Boolean(), nullable=False),
        sa.Column("is_file_message", sa.Boolean(), nullable=False),
        sa.Column("file_message_id", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(["usage_id"], ["usage.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_transcription_states_usage_id"), "transcription_states", ["usage_id"], unique=False
    )
    # Add unique constraint for (message_id, chat_id)
    # Add index for (message_id, chat_id) lookup
    with op.batch_alter_table("transcription_states", schema=None) as batch_op:
        batch_op.create_unique_constraint(
            "uq_transcription_states_message_chat", ["message_id", "chat_id"]
        )
        batch_op.create_index("ix_transcription_states_message_chat", ["message_id", "chat_id"])

    op.create_table(
        "transcription_variants",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("usage_id", sa.Integer(), nullable=False),
        sa.Column("mode", sa.String(length=20), nullable=False),
        sa.Column("length_level", sa.String(length=10), nullable=False),
        sa.Column("emoji_level", sa.Integer(), nullable=False),
        sa.Column("timestamps_enabled", sa.Boolean(), nullable=False),
        sa.Column("text_content", sa.String(), nullable=False),
        sa.Column("generated_by", sa.String(length=50), nullable=True),
        sa.Column("llm_model", sa.String(length=100), nullable=True),
        sa.Column("processing_time_seconds", sa.Float(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("last_accessed_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(["usage_id"], ["usage.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_transcription_variants_usage_id"),
        "transcription_variants",
        ["usage_id"],
        unique=False,
    )
    # Add unique constraint for variant parameters
    # Add index for last_accessed_at for cleanup queries
    with op.batch_alter_table("transcription_variants", schema=None) as batch_op:
        batch_op.create_unique_constraint(
            "uq_transcription_variants_params",
            ["usage_id", "mode", "length_level", "emoji_level", "timestamps_enabled"],
        )
        batch_op.create_index("ix_transcription_variants_last_accessed", ["last_accessed_at"])
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop transcription_variants (reverse order)
    with op.batch_alter_table("transcription_variants", schema=None) as batch_op:
        batch_op.drop_index("ix_transcription_variants_last_accessed")
        batch_op.drop_constraint("uq_transcription_variants_params", type_="unique")
    op.drop_index(op.f("ix_transcription_variants_usage_id"), table_name="transcription_variants")
    op.drop_table("transcription_variants")

    # Drop transcription_states
    with op.batch_alter_table("transcription_states", schema=None) as batch_op:
        batch_op.drop_index("ix_transcription_states_message_chat")
        batch_op.drop_constraint("uq_transcription_states_message_chat", type_="unique")
    op.drop_index(op.f("ix_transcription_states_usage_id"), table_name="transcription_states")
    op.drop_table("transcription_states")

    # Drop transcription_segments
    with op.batch_alter_table("transcription_segments", schema=None) as batch_op:
        batch_op.drop_constraint("uq_transcription_segments_usage_segment", type_="unique")
    op.drop_index(op.f("ix_transcription_segments_usage_id"), table_name="transcription_segments")
    op.drop_table("transcription_segments")
    # ### end Alembic commands ###
